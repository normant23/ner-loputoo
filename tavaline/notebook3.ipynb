{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb2ced7-e8e6-4827-b4ae-c24039754c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.ner import NERModel\n",
    "\n",
    "import os\n",
    "import estnltk\n",
    "from estnltk import Text\n",
    "from estnltk.converters import text_to_json, json_to_text\n",
    "\n",
    "import torch\n",
    "\n",
    "from new_ner_tagger import NewNerTagger\n",
    "from new2_ner_tagger import New2NerTagger\n",
    "\n",
    "from words_tokenization import preprocess_words\n",
    "from sentence_tokenization import sentence_tokenizer\n",
    "from sentence_tokenization import postfix_sentence_breaks_inside_parentheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89231de-e283-41fe-a839-e8e9d43e816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new2_ner = New2NerTagger(model_location='outputs/best_model', output_layer='new2_ner', batch_size=1200)\n",
    "name = '1938-01-31.json'\n",
    "with open(os.path.join('data/koik', name), \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "text_import = json_to_text(json_text=content)\n",
    "print(text_import.sentences[4])\n",
    "text_import.pop_layer('sentences')\n",
    "text_import.pop_layer('words')\n",
    "text_import.pop_layer('compound_tokens')\n",
    "preprocess_words( text_import )\n",
    "sentence_tokenizer.tag( text_import )\n",
    "postfix_sentence_breaks_inside_parentheses( text_import, doc_name='' )\n",
    "print(text_import.layers)\n",
    "new2_ner.tag(text_import)\n",
    "print(text_import.layers)\n",
    "text_import.new2_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debf7e3c-2750-4d77-8ec5-ba089896c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_import.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1233749f-28a1-49ef-8b1e-a636bdfef518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kuusloo',\n",
       " ',',\n",
       " 'A. Kuum',\n",
       " ',',\n",
       " 'P. Tarvel',\n",
       " ',',\n",
       " 'J. Sütt',\n",
       " 'ja',\n",
       " 'A. Linkberg',\n",
       " '.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_import.sentences[5].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae05b0dc-c3c7-4cb1-ae2f-719f75b7996c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original NumPy values:\n",
      "np_float32: 3.141590118408203 (type: <class 'numpy.float32'>)\n",
      "np_int64: 42 (type: <class 'numpy.int64'>)\n",
      "np_array: [1.1 2.2 3.3] (type: <class 'numpy.ndarray'>)\n",
      "\n",
      "Method 1 (Direct serialization) error: Object of type float32 is not JSON serializable\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Create some NumPy values\n",
    "np_float32 = np.float32(3.14159)\n",
    "np_int64 = np.int64(42)\n",
    "np_array = np.array([1.1, 2.2, 3.3], dtype=np.float32)\n",
    "\n",
    "print(\"Original NumPy values:\")\n",
    "print(f\"np_float32: {np_float32} (type: {type(np_float32)})\")\n",
    "print(f\"np_int64: {np_int64} (type: {type(np_int64)})\")\n",
    "print(f\"np_array: {np_array} (type: {type(np_array)})\")\n",
    "\n",
    "# Method 1: This will fail - trying to directly serialize NumPy types\n",
    "try:\n",
    "    json_str = json.dumps({\"float32\": np_float32, \"int64\": np_int64, \"array\": np_array})\n",
    "    print(\"\\nMethod 1 (Direct serialization) result:\", json_str)\n",
    "except TypeError as e:\n",
    "    print(\"\\nMethod 1 (Direct serialization) error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec4e1b10-6cdf-4c42-84fc-61efa0f3e03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "new_ner = NewNerTagger(model_location='outputs/best_model', output_layer='new_ner', batch_size=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bf4dc98-c33a-44e6-9345-39bfcdcad11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bert_ner', 'tokens', 'compound_tokens', 'textline_info', 'words', 'ne_gold_a', 'sentences'}\n",
      "{'bert_ner', 'tokens', 'compound_tokens', 'textline_info', 'words', 'new_ner', 'ne_gold_a', 'sentences'}\n"
     ]
    }
   ],
   "source": [
    "name = '1922-04-24_manual_annotated.json'\n",
    "with open(os.path.join('data/output4', name), \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "text_import = json_to_text(json_text=content)\n",
    "print(text_import.layers)\n",
    "new_ner.tag(text_import)\n",
    "print(text_import.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26e4c67d-5b70-4952-bd94-ea3306ee4d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584 Kurs-Olesk 3214 3224 ['.', 'Lwol', '.', 'M', '.', 'Kurs-Olesk', 'arwab']\n",
      "676 Kurs-Oleski 3773 3784 [':', 'Lwol', '.', 'M', '.', 'Kurs-Oleski', 'ettepanek']\n",
      "2184 Kurs-Olesk 12848 12858 ['.', 'Lwol', '.', 'M', '.', 'Kurs-Olesk', 'soowitab']\n",
      "582 M.Kurs-Olesk 3212 3224 ['pealt', 'oleks', '.', 'Lwol', '.', 'M.Kurs-Olesk', 'arwab', ',', 'et', 'linna']\n",
      "672 M.Kurs-Oleski 3771 3784 ['said', 'hääli', ':', 'Lwol', '.', 'M.Kurs-Oleski', 'ettepanek', '-', '6', 'poolt']\n",
      "1805 M.Kurs 10547 10553 ['\"', '.', '-', 'Lwol', '.', 'M.Kurs', 'Olesk', 'awaldab', 'soowi', ',']\n",
      "2178 M.Kurs-Olesk 12846 12858 ['wörra', '\"', '.', 'Lwol', '.', 'M.Kurs-Olesk', 'soowitab', 'nimetatud', 'nöuande-punkti', 'linna']\n",
      "106 EnvelopingSpan(['-', 'Lwol', '.', 'M.Kurs', 'Olesk', 'awaldab', 'soowi', ',', 'et', 'linnawalitsus', 'ise', 'katsuks', 'elumajasid', 'ehitada', 'ja', 'et', 'ülejääw', 'osa', 'ehituslaenust', 'saaks', 'laiematele', 'hulkadele', 'eeskätt', 'ehitus-ühingutele', 'laenuks', 'antud', '.'], [{}])\n",
      "0.8153846153846154\n"
     ]
    }
   ],
   "source": [
    "name = '1922-04-24_manual_annotated.json'\n",
    "with open(os.path.join('data/output4', name), \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "text_import = json_to_text(json_text=content)\n",
    "for nr, i in enumerate(text_import.words):\n",
    "    if i.text.startswith('Kurs'):\n",
    "        print(nr, i.text, i.start, i.end, text_import.words[nr-5: nr+2].text)\n",
    "\n",
    "text_import.pop_layer('sentences')\n",
    "text_import.pop_layer('words')\n",
    "text_import.pop_layer('compound_tokens')\n",
    "\n",
    "preprocess_words( text_import )\n",
    "sentence_tokenizer.tag( text_import )\n",
    "postfix_sentence_breaks_inside_parentheses( text_import, doc_name='' )\n",
    "\n",
    "for nr, i in enumerate(text_import.words):\n",
    "    if i.text.startswith('M.Kurs'):\n",
    "        print(nr, i.text, i.start, i.end, text_import.words[nr-5: nr+5].text)\n",
    "\n",
    "for nr, i in enumerate(text_import.sentences):\n",
    "    if i.start < 10547 and i.end > 10553:\n",
    "        print(nr, i)\n",
    "        print(nr/len(text_import.sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d651634-50ce-450d-8eb1-049c66760679",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '1922-04-24.json'\n",
    "with open(os.path.join('data/koik', name), \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "text_import = json_to_text(json_text=content)\n",
    "text_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc58e8c7-bcae-43c3-8c9a-4a2384c4f867",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_import.new_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac1401dc-8cdf-4f6d-ab5b-bf09006e4f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338\n",
      "1918-01-11.json\n",
      "{'tokens', 'table_regions', 'words', 'compound_tokens', 'textline_info', 'appendix_regions', 'sentences'}\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('data/koik')))\n",
    "for name in os.listdir('data/koik'):\n",
    "    print(name)\n",
    "    with open('data/koik' + \"/\" + name, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "    text_import = json_to_text(json_text=content)\n",
    "    print(text_import.layers)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f0579c-179e-489b-806c-9cfc284454ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_import.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74729eb0-ef87-4ec6-8980-7993c8589f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens', 'table_regions', 'words', 'compound_tokens', 'textline_info', 'appendix_regions', 'sentences'}\n",
      "584 7885\n",
      "{'Lw', 'Ln', 'E.Kapsta'}\n",
      "{'tokens', 'table_regions', 'words', 'compound_tokens', 'textline_info', 'appendix_regions', 'sentences'}\n",
      "584 7891\n"
     ]
    }
   ],
   "source": [
    "name = '1923-12-28_1923-12-29.json'\n",
    "with open(os.path.join('data/koik', name), \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "text_import = json_to_text(json_text=content)\n",
    "print(text_import.layers)\n",
    "print(len(text_import.sentences), len(text_import.words))\n",
    "#vana lausestus ja sõnestus maha\n",
    "alg = set(text_import.words.text)\n",
    "text_import.pop_layer('sentences')\n",
    "text_import.pop_layer('words')\n",
    "text_import.pop_layer('compound_tokens')\n",
    "#uus lausestus ja sõnestus\n",
    "preprocess_words( text_import )\n",
    "sentence_tokenizer.tag( text_import )\n",
    "postfix_sentence_breaks_inside_parentheses( text_import, doc_name='' )\n",
    "prst = set(text_import.words.text)\n",
    "print(prst - alg)\n",
    "print(text_import.layers)\n",
    "print(len(text_import.sentences), len(text_import.words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff1540d-b179-4f09-9379-c45cc3ae5a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '1940-09-26.json'\n",
    "with open(os.path.join('data/koik', name), \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "text_import = json_to_text(json_text=content)\n",
    "text_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60775d58-c1d3-4e80-b1f4-db24ce38cd4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Tallinna',\n",
       "  'wene',\n",
       "  'teater',\n",
       "  'kawatseb',\n",
       "  'etendusi',\n",
       "  'korraldada',\n",
       "  'Tartus',\n",
       "  ',',\n",
       "  'Saksa',\n",
       "  'teatris',\n",
       "  ',',\n",
       "  'käesolwa',\n",
       "  'suwehooaja',\n",
       "  'jooksul',\n",
       "  '2',\n",
       "  '-',\n",
       "  '3',\n",
       "  'korda',\n",
       "  'nädalas',\n",
       "  '.']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = '1922-04-24_manual_annotated.json'\n",
    "with open(os.path.join('output4', name), \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "text_import = json_to_text(json_text=content)\n",
    "examples = [text_import.sentences[35].text]\n",
    "labels = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d01a30ad-cf48-4650-8f2f-1c39cfe78521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:ner_model.py:1884:  Converting to features started.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2cc58cef394d46ab811ce166952050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b701e4be3b4d41a3937e9b27f138ac6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Prediction:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Norman\\anaconda3\\Lib\\site-packages\\simpletransformers\\ner\\ner_model.py:1643: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.ner import NERModel\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model\n",
    "model = NERModel(\n",
    "    \"bert\",\n",
    "    \"outputs/\",  # or the specific path where your model was saved\n",
    "    args={\"use_cuda\": True}  # set to True if you have a GPU\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "predictions, raw_outputs = model.predict(examples, split_on_space=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47463cfc-8963-464b-adc5-2644606bcb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Tallinna': 'B-ORG'}\n",
      "{'Tallinna': [[1.306, -0.7544, -2.135, 2.178, -0.4844, 1.096, -2.078]]}\n",
      "[1.306, -0.7544, -2.135, 2.178, -0.4844, 1.096, -2.078]\n",
      "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']\n",
      "[0.21916159234075944, 0.027931378340152187, 0.0070243285796242816, 0.5242033254874603, 0.03658982732366599, 0.1776558736201844, 0.007433674308153444]\n",
      "\n",
      "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']\n",
      "[0.21916158497333527, 0.027931377291679382, 0.0070243277586996555, 0.5242033004760742, 0.03658982738852501, 0.17765586078166962, 0.007433673832565546]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[0][0])\n",
    "print(raw_outputs[0][0])\n",
    "print(list(raw_outputs[0][0].values())[0][0])\n",
    "subword_logits = list(raw_outputs[0][0].values())[0][0]\n",
    "subword_logits_np = np.array(subword_logits, dtype=float)\n",
    "exp_logits = np.exp(subword_logits_np)\n",
    "probs = exp_logits / np.sum(exp_logits)\n",
    "\n",
    "print(labels)\n",
    "print(list(probs))\n",
    "\n",
    "\n",
    "print()\n",
    "subword_logits = list(raw_outputs[0][0].values())[0][0]\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "logits_tensor = torch.tensor(subword_logits, dtype=torch.float)\n",
    "\n",
    "# Apply softmax\n",
    "probs = torch.softmax(logits_tensor, dim=0)\n",
    "\n",
    "# Convert back to list if needed\n",
    "probs_list = probs.tolist()\n",
    "\n",
    "print(labels)\n",
    "print(probs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc74f7cf-2e03-4790-a1f6-c745c90d3888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions structure:\n",
      "Type of predictions: <class 'list'>\n",
      "Length of predictions: 1\n",
      "Type of first element: <class 'list'>\n",
      "First element content: [{'Tartu-Wõru': 'B-ORG'}, {'Rahukogult': 'I-ORG'}, {'on': 'O'}]\n",
      "\n",
      "Raw outputs structure:\n",
      "Type of raw_outputs: <class 'list'>\n",
      "Length of raw_outputs: 1\n",
      "Type of first element: <class 'list'>\n",
      "Shape of first element: (33,)\n"
     ]
    }
   ],
   "source": [
    "# Try to understand the structure of the predictions and raw_outputs\n",
    "print(\"Predictions structure:\")\n",
    "print(f\"Type of predictions: {type(predictions)}\")\n",
    "print(f\"Length of predictions: {len(predictions)}\")\n",
    "if len(predictions) > 0:\n",
    "    print(f\"Type of first element: {type(predictions[0])}\")\n",
    "    print(f\"First element content: {predictions[0][:3]}\")  # Show first 3 items\n",
    "\n",
    "print(\"\\nRaw outputs structure:\")\n",
    "print(f\"Type of raw_outputs: {type(raw_outputs)}\")\n",
    "print(f\"Length of raw_outputs: {len(raw_outputs)}\")\n",
    "if len(raw_outputs) > 0:\n",
    "    print(f\"Type of first element: {type(raw_outputs[0])}\")\n",
    "    print(f\"Shape of first element: {np.array(raw_outputs[0]).shape if isinstance(raw_outputs[0], list) else 'Not a list'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "532b1e2e-bfc2-4df7-ad76-2f881282e3c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'Tartu-Wõru': [[0.1251,\n",
       "     -2.113,\n",
       "     -1.55,\n",
       "     0.2089,\n",
       "     -0.27,\n",
       "     3.324,\n",
       "     0.5864,\n",
       "     1.405,\n",
       "     -0.83],\n",
       "    [2.574, -1.553, -1.815, -1.407, -1.641, 1.196, 2.074, -0.353, 0.9487],\n",
       "    [-0.01715, -1.788, -1.248, -0.12494, -0.6807, 2.621, 1.722, 0.86, -0.0854],\n",
       "    [0.1825, -1.383, -0.739, -0.9233, -0.4084, 1.719, 2.828, 0.1686, 0.41]]},\n",
       "  {'Rahukogult': [[0.552,\n",
       "     -1.691,\n",
       "     -1.926,\n",
       "     -1.804,\n",
       "     -1.123,\n",
       "     1.25,\n",
       "     4.004,\n",
       "     -0.3386,\n",
       "     0.2905],\n",
       "    [1.928, -1.395, -2.404, -1.797, -1.204, -0.644, 4.53, -0.664, 0.5283],\n",
       "    [5.04, -1.356, -1.839, -0.9346, -0.7925, -1.643, 2.797, -0.9004, 0.828]]},\n",
       "  {'on': [[7.797,\n",
       "     -2.33,\n",
       "     -1.873,\n",
       "     -1.586,\n",
       "     -1.402,\n",
       "     -0.9727,\n",
       "     -0.8555,\n",
       "     -0.5146,\n",
       "     -0.536]]},\n",
       "  {'saadud': [[8.15,\n",
       "     -2.342,\n",
       "     -1.872,\n",
       "     -1.328,\n",
       "     -1.293,\n",
       "     -0.9883,\n",
       "     -0.7046,\n",
       "     -0.78,\n",
       "     -0.666]]},\n",
       "  {'teadaanded': [[7.64,\n",
       "     -1.977,\n",
       "     -1.713,\n",
       "     -1.534,\n",
       "     -1.13,\n",
       "     -0.6514,\n",
       "     -1.091,\n",
       "     -0.4844,\n",
       "     -1.107],\n",
       "    [7.75,\n",
       "     -2.021,\n",
       "     -1.638,\n",
       "     -1.352,\n",
       "     -1.221,\n",
       "     -0.5044,\n",
       "     -0.796,\n",
       "     -0.5347,\n",
       "     -0.5776]]},\n",
       "  {'selle': [[7.82,\n",
       "     -2.049,\n",
       "     -2.615,\n",
       "     -1.248,\n",
       "     -1.576,\n",
       "     -0.6133,\n",
       "     -0.3865,\n",
       "     -0.259,\n",
       "     -0.2559]]},\n",
       "  {'kohta,': [[7.96,\n",
       "     -2.045,\n",
       "     -2.287,\n",
       "     -1.087,\n",
       "     -1.464,\n",
       "     -0.7695,\n",
       "     -0.2764,\n",
       "     -0.2837,\n",
       "     -0.619],\n",
       "    [7.25, -2.521, -2.777, -2.174, -0.603, -0.1807, 0.428, -0.4985, -0.1768]]},\n",
       "  {'et': [[7.832,\n",
       "     -1.892,\n",
       "     -2.463,\n",
       "     -1.387,\n",
       "     -1.163,\n",
       "     -0.581,\n",
       "     -0.7896,\n",
       "     -0.7656,\n",
       "     -0.9]]},\n",
       "  {'lwol.': [[6.72,\n",
       "     -2.318,\n",
       "     -2.896,\n",
       "     0.1377,\n",
       "     -1.101,\n",
       "     0.2915,\n",
       "     -0.2336,\n",
       "     -0.4233,\n",
       "     -1.23],\n",
       "    [6.023,\n",
       "     -2.463,\n",
       "     -2.068,\n",
       "     0.2942,\n",
       "     -0.6343,\n",
       "     0.5254,\n",
       "     -0.11053,\n",
       "     -0.09393,\n",
       "     -0.5938],\n",
       "    [4.758, -1.698, -1.914, 2.125, -0.4905, 0.1287, -0.457, -0.2137, -0.4805],\n",
       "    [5.582,\n",
       "     -2.45,\n",
       "     -2.488,\n",
       "     0.1292,\n",
       "     0.571,\n",
       "     0.0926,\n",
       "     -0.012215,\n",
       "     0.1166,\n",
       "     -0.1046]]},\n",
       "  {'JohanOskar': [[0.2327,\n",
       "     -1.498,\n",
       "     -1.469,\n",
       "     4.53,\n",
       "     1.837,\n",
       "     1.138,\n",
       "     -1.51,\n",
       "     -0.731,\n",
       "     -1.3],\n",
       "    [0.01057, -0.956, -1.092, 1.949, 2.95, 0.6616, -0.9434, -0.725, -1.13],\n",
       "    [1.395, -2.12, -1.72, 1.8, 2.174, 0.03845, 0.1761, -0.678, -1.197],\n",
       "    [2.113, -1.844, -2.078, 2.426, 1.656, -0.198, 0.489, -0.6226, -0.878]]},\n",
       "  {'Rütli': [[0.1882,\n",
       "     -1.596,\n",
       "     -2.062,\n",
       "     2.188,\n",
       "     4.496,\n",
       "     -0.314,\n",
       "     -0.3674,\n",
       "     -0.6353,\n",
       "     -1.25],\n",
       "    [1.396,\n",
       "     -1.478,\n",
       "     -1.447,\n",
       "     1.177,\n",
       "     1.972,\n",
       "     -0.8706,\n",
       "     -0.2568,\n",
       "     -0.2032,\n",
       "     -0.9995]]},\n",
       "  {'ja': [[6.848,\n",
       "     -2.178,\n",
       "     -2.812,\n",
       "     -1.893,\n",
       "     -0.4077,\n",
       "     -0.9775,\n",
       "     0.2856,\n",
       "     -0.99,\n",
       "     -0.6196]]},\n",
       "  {'teiste': [[4.836,\n",
       "     -2.31,\n",
       "     -2.63,\n",
       "     -0.2886,\n",
       "     0.1667,\n",
       "     1.412,\n",
       "     0.2998,\n",
       "     -0.2522,\n",
       "     -1.268]]},\n",
       "  {'kaebus': [[1.67,\n",
       "     -1.9795,\n",
       "     -1.811,\n",
       "     -0.3362,\n",
       "     -0.4915,\n",
       "     1.796,\n",
       "     0.6084,\n",
       "     -0.4072,\n",
       "     -0.928]]},\n",
       "  {'ja': [[6.58,\n",
       "     -2.28,\n",
       "     -2.682,\n",
       "     -1.702,\n",
       "     -0.8423,\n",
       "     -0.3394,\n",
       "     0.744,\n",
       "     -0.759,\n",
       "     -0.848]]},\n",
       "  {'Kohtu-': [[0.911,\n",
       "     -1.8125,\n",
       "     -2.498,\n",
       "     -0.451,\n",
       "     -1.244,\n",
       "     3.305,\n",
       "     2.11,\n",
       "     0.1709,\n",
       "     -1.407],\n",
       "    [2.129, -1.127, -2.537, -1.586, -0.596, 0.8374, 3.49, -0.805, 0.015434]]},\n",
       "  {'ja': [[2.434,\n",
       "     -1.679,\n",
       "     -2.441,\n",
       "     -1.459,\n",
       "     -0.521,\n",
       "     0.115,\n",
       "     3.418,\n",
       "     -0.704,\n",
       "     -0.2664]]},\n",
       "  {'Siseministeeriumi': [[0.9224,\n",
       "     -1.635,\n",
       "     -2.658,\n",
       "     -0.7744,\n",
       "     -0.4583,\n",
       "     2.39,\n",
       "     3.395,\n",
       "     -0.12305,\n",
       "     -0.961],\n",
       "    [2.094, -0.918, -2.184, -0.8105, -0.421, 0.08545, 3.998, -1.138, 0.4163]]},\n",
       "  {'protest': [[5.504,\n",
       "     -2.283,\n",
       "     -2.262,\n",
       "     -0.5757,\n",
       "     -0.97,\n",
       "     -0.1877,\n",
       "     0.7485,\n",
       "     -0.68,\n",
       "     -1.248]]},\n",
       "  {'Linnawolikogu': [[0.01926,\n",
       "     -2.1,\n",
       "     -1.889,\n",
       "     -0.4495,\n",
       "     -1.69,\n",
       "     4.934,\n",
       "     0.6855,\n",
       "     0.2002,\n",
       "     -1.139],\n",
       "    [0.8057, -1.702, -2.383, -1.034, -1.471, 2.428, 3.785, -0.2334, -0.319],\n",
       "    [1.358, -1.435, -2.393, -1.765, -1.066, 0.8936, 4.184, -0.6797, 0.1125],\n",
       "    [1.424, -1.683, -2.37, -1.719, -0.751, -0.01122, 4.32, -0.8506, 0.1064],\n",
       "    [4.113, -1.539, -2.514, -1.445, -0.789, -1.41, 3.264, -0.789, 0.2742]]},\n",
       "  {'24.jaanuari': [[7.273,\n",
       "     -2.26,\n",
       "     -2.46,\n",
       "     -0.519,\n",
       "     -1.365,\n",
       "     -0.782,\n",
       "     0.2328,\n",
       "     -0.743,\n",
       "     -0.11945],\n",
       "    [6.355, -2.46, -2.709, -1.765, 0.4446, -0.03494, 0.736, -0.538, -0.00759],\n",
       "    [6.74,\n",
       "     -2.322,\n",
       "     -2.053,\n",
       "     -0.6255,\n",
       "     -1.286,\n",
       "     -0.539,\n",
       "     -0.003431,\n",
       "     -0.5747,\n",
       "     -0.652]]},\n",
       "  {'s.a.': [[6.453,\n",
       "     -1.988,\n",
       "     -1.856,\n",
       "     -0.04388,\n",
       "     -0.96,\n",
       "     0.06824,\n",
       "     -0.1445,\n",
       "     -0.0654,\n",
       "     -0.794],\n",
       "    [6.38,\n",
       "     -2.475,\n",
       "     -2.713,\n",
       "     -1.759,\n",
       "     0.4402,\n",
       "     -0.02722,\n",
       "     0.7407,\n",
       "     -0.543,\n",
       "     -9.95e-05],\n",
       "    [6.695,\n",
       "     -2.053,\n",
       "     -2.248,\n",
       "     -0.6943,\n",
       "     -1.246,\n",
       "     -0.4954,\n",
       "     -1.215,\n",
       "     -0.2632,\n",
       "     -0.1597],\n",
       "    [6.71, -2.742, -2.756, -1.5625, 0.1284, 0.2335, 0.7954, -0.3716, 0.1248]]},\n",
       "  {'koosoleku': [[6.277,\n",
       "     -2.277,\n",
       "     -2.074,\n",
       "     -0.79,\n",
       "     -1.466,\n",
       "     -0.1411,\n",
       "     -0.3901,\n",
       "     -0.5605,\n",
       "     -0.258]]},\n",
       "  {'otsuste': [[7.812,\n",
       "     -2.31,\n",
       "     -2.295,\n",
       "     -1.012,\n",
       "     -1.381,\n",
       "     -0.71,\n",
       "     -1.291,\n",
       "     -0.701,\n",
       "     -0.4185]]},\n",
       "  {'wastu': [[7.24,\n",
       "     -2.596,\n",
       "     -2.416,\n",
       "     -1.802,\n",
       "     -0.501,\n",
       "     -0.2139,\n",
       "     -0.692,\n",
       "     -0.4038,\n",
       "     -0.1593],\n",
       "    [7.65,\n",
       "     -2.178,\n",
       "     -2.994,\n",
       "     -1.456,\n",
       "     -0.9004,\n",
       "     -1.397,\n",
       "     -0.4927,\n",
       "     -0.818,\n",
       "     -0.3447]]},\n",
       "  {'on': [[8.28,\n",
       "     -2.18,\n",
       "     -2.283,\n",
       "     -1.697,\n",
       "     -1.491,\n",
       "     -0.854,\n",
       "     -1.179,\n",
       "     -0.481,\n",
       "     -0.449]]},\n",
       "  {'jäetud': [[8.43,\n",
       "     -1.997,\n",
       "     -2.291,\n",
       "     -1.305,\n",
       "     -1.421,\n",
       "     -0.8623,\n",
       "     -1.086,\n",
       "     -0.7363,\n",
       "     -0.566]]},\n",
       "  {'tagajärjeta': [[7.98,\n",
       "     -2.281,\n",
       "     -2.186,\n",
       "     -1.754,\n",
       "     -1.488,\n",
       "     -0.737,\n",
       "     -1.095,\n",
       "     -0.4946,\n",
       "     -0.578],\n",
       "    [8.195, -2.414, -2.53, -1.968, -1.202, -1.27, -0.937, -0.3591, -0.7417]]},\n",
       "  {'nii': [[5.51,\n",
       "     -2.467,\n",
       "     -3.072,\n",
       "     -0.779,\n",
       "     -1.573,\n",
       "     0.7563,\n",
       "     -0.1757,\n",
       "     0.5605,\n",
       "     -0.386]]},\n",
       "  {'Rahukogus': [[0.646,\n",
       "     -2.658,\n",
       "     -2.041,\n",
       "     -0.4531,\n",
       "     -1.527,\n",
       "     4.062,\n",
       "     0.3005,\n",
       "     0.5186,\n",
       "     -0.652],\n",
       "    [1.943, -1.976, -1.839, -2.502, -1.16, 0.004265, 4.16, -0.302, 0.5986]]},\n",
       "  {'kui': [[6.88,\n",
       "     -2.182,\n",
       "     -2.443,\n",
       "     -1.396,\n",
       "     -1.571,\n",
       "     -0.637,\n",
       "     0.756,\n",
       "     -0.599,\n",
       "     0.4058]]},\n",
       "  {'ka': [[6.72,\n",
       "     -2.488,\n",
       "     -2.836,\n",
       "     -1.393,\n",
       "     -1.245,\n",
       "     -0.6724,\n",
       "     -0.3694,\n",
       "     -0.155,\n",
       "     -0.0695]]},\n",
       "  {'Riigikohtus.': [[0.9004,\n",
       "     -2.514,\n",
       "     -2.002,\n",
       "     0.0424,\n",
       "     -0.5493,\n",
       "     3.516,\n",
       "     0.1769,\n",
       "     0.1764,\n",
       "     -1.316],\n",
       "    [2.736, -1.908, -1.48, -1.813, -0.912, -0.4907, 3.086, -0.1896, 0.5054],\n",
       "    [6.35,\n",
       "     -2.457,\n",
       "     -2.709,\n",
       "     -1.77,\n",
       "     0.4468,\n",
       "     -0.03806,\n",
       "     0.7383,\n",
       "     -0.5396,\n",
       "     -0.007595]]}]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d70d2247-6d5d-4628-b99d-0df6c0f1efa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    2,  1055,   251,   836, 24919, 18766,   959,    61,    42,  3242,\n",
      "          1148, 45725,   143,   580,    11,    74,    72, 36744, 49887,    15,\n",
      "         20253, 49950,  9519, 49894, 22756,  4675,    37,  1457, 36617,    15,\n",
      "             3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n",
      "Token: Tartu\n",
      "  - B-ORG: 0.5836\n",
      "\n",
      "Token: -\n",
      "  - I-ORG: 0.6371\n",
      "\n",
      "Token: W\n",
      "  - B-ORG: 0.7368\n",
      "\n",
      "Token: ##õru\n",
      "  - I-ORG: 0.6951\n",
      "\n",
      "Token: Rahu\n",
      "  - I-ORG: 0.9218\n",
      "\n",
      "Token: ##kogu\n",
      "  - I-ORG: 0.9336\n",
      "\n",
      "Token: ##lt\n",
      "  - O: 0.6058\n",
      "\n",
      "Token: on\n",
      "  - O: 0.9990\n",
      "\n",
      "Token: saadud\n",
      "  - O: 0.9996\n",
      "\n",
      "Token: teada\n",
      "  - O: 0.9995\n",
      "\n",
      "Token: ##anded\n",
      "  - O: 0.9996\n",
      "\n",
      "Token: selle\n",
      "  - O: 0.9994\n",
      "\n",
      "Token: kohta\n",
      "  - O: 0.9993\n",
      "\n",
      "Token: ,\n",
      "  - O: 0.9983\n",
      "\n",
      "Token: et\n",
      "  - O: 0.9991\n",
      "\n",
      "Token: l\n",
      "  - O: 0.9958\n",
      "\n",
      "Token: ##wo\n",
      "  - O: 0.9869\n",
      "\n",
      "Token: ##l\n",
      "  - O: 0.9636\n",
      "\n",
      "Token: .\n",
      "  - O: 0.9327\n",
      "\n",
      "Token: Johan\n",
      "  - B-PER: 0.9624\n",
      "\n",
      "Token: ##O\n",
      "  - I-PER: 0.7974\n",
      "\n",
      "Token: ##ska\n",
      "  - I-PER: 0.6857\n",
      "\n",
      "Token: ##r\n",
      "  - B-PER: 0.3750\n",
      "\n",
      "Token: Rü\n",
      "  - I-PER: 0.8464\n",
      "\n",
      "Token: ##tli\n",
      "  - I-PER: 0.7301\n",
      "\n",
      "Token: ja\n",
      "  - O: 0.9980\n",
      "\n",
      "Token: teiste\n",
      "  - O: 0.9901\n",
      "\n",
      "Token: kaebus\n",
      "  - O: 0.9967\n",
      "\n",
      "Token: .\n",
      "  - O: 0.9965\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# Path to your finetuned model\n",
    "model_path = \"outputs/\"  # or wherever your model was saved\n",
    "\n",
    "# Load components\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "config = AutoConfig.from_pretrained(model_path)\n",
    "\n",
    "# Get the id2label mapping\n",
    "id2label = config.id2label\n",
    "label2id = config.label2id\n",
    "\n",
    "def get_ner_predictions(text, get_top_n=1):\n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    " \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get probabilities\n",
    "    logits = outputs.logits.squeeze()  # Shape: [sequence_length, num_labels]\n",
    "    probs = torch.softmax(logits, dim=-1)  # Convert logits to probabilities\n",
    "    \n",
    "    # Get tokens from tokenizer\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "    \n",
    "    # Get predictions for each token\n",
    "    predictions = []\n",
    "    for i, token in enumerate(tokens):\n",
    "        # Skip special tokens\n",
    "        if token in [tokenizer.cls_token, tokenizer.sep_token, tokenizer.pad_token]:\n",
    "            continue\n",
    "            \n",
    "        token_probs = probs[i]\n",
    "        top_indices = torch.topk(token_probs, min(get_top_n, len(id2label))).indices\n",
    "        \n",
    "        token_predictions = []\n",
    "        for idx in top_indices:\n",
    "            label = id2label[idx.item()]\n",
    "            probability = token_probs[idx].item()\n",
    "            token_predictions.append({\"label\": label, \"probability\": probability})\n",
    "        \n",
    "        predictions.append({\n",
    "            \"token\": token,\n",
    "            \"predictions\": token_predictions\n",
    "        })\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Example usage\n",
    "text = \"Tartu-Wõru Rahukogult on saadud teadaanded selle kohta, et lwol. JohanOskar Rütli ja teiste kaebus.\"\n",
    "results = get_ner_predictions(text)\n",
    "\n",
    "# Print results\n",
    "for token_result in results:\n",
    "    print(f\"Token: {token_result['token']}\")\n",
    "    for pred in token_result['predictions']:\n",
    "        print(f\"  - {pred['label']}: {pred['probability']:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4a3f936-96dd-46c4-84bb-77c907f7e8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer(name='new_ner', attributes=('nertag', 'prob'), spans=SL[EnvelopingSpan(['Tartu', 'Linnawolikogu'], [{'nertag': 'ORG', 'prob': 0.9738}]),\n",
      "EnvelopingSpan(['a.'], [{'nertag': 'PER', 'prob': 0.5038}]),\n",
      "EnvelopingSpan(['Lui', 'Olesk', '.'], [{'nertag': 'PER', 'prob': 0.9113}]),\n",
      "EnvelopingSpan(['lnw', '.'], [{'nertag': 'PER', 'prob': 0.4999}]),\n",
      "EnvelopingSpan(['Wirkhaus'], [{'nertag': 'PER', 'prob': 0.7854}]),\n",
      "EnvelopingSpan(['Meyer', ',', 'Rebane-Sild', ',', 'Engelhardt'], [{'nertag': 'PER', 'prob': 0.8055}]),\n",
      "EnvelopingSpan(['Ottho'], [{'nertag': 'PER', 'prob': 0.8044}]),\n",
      "EnvelopingSpan(['Bädge'], [{'nertag': 'PER', 'prob': 0.7674}]),\n",
      "EnvelopingSpan(['Rosenthal'], [{'nertag': 'PER', 'prob': 0.7737}]),\n",
      "EnvelopingSpan(['Ostrat'], [{'nertag': 'PER', 'prob': 0.888}])])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import estnltk\n",
    "from estnltk import Text\n",
    "from estnltk.converters import text_to_json, json_to_text\n",
    "from new_ner_tagger import NewNerTagger\n",
    "\n",
    "input_folder = 'data/koik'\n",
    "output_folder = 'data/temp'\n",
    "new_ner = NewNerTagger(model_location='outputs/best_model', output_layer='new_ner', batch_size=850, device='cpu')\n",
    "\n",
    "for name in os.listdir(input_folder)[:5]:\n",
    "    with open(os.path.join(input_folder, name), \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "    text_import = json_to_text(json_text=content)\n",
    "    new_ner.tag(text_import)\n",
    "    text_to_json(text_import, file=(output_folder + \"/\" + name))\n",
    "\n",
    "with open(os.path.join(output_folder, os.listdir(output_folder)[0]), \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "text_import = json_to_text(json_text=content)\n",
    "print(text_import.new_ner[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
