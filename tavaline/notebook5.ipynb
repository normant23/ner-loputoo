{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2e51461-b68d-48dd-9648-7f90bb11173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import estnltk\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from estnltk import Text\n",
    "from estnltk.converters import text_to_json, json_to_text\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018faea2-168f-4171-8a34-b78703436e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10419 2605 13024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>LOC_count</th>\n",
       "      <th>PER_count</th>\n",
       "      <th>ORG_count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>sentences</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>3630</td>\n",
       "      <td>10323</td>\n",
       "      <td>7654</td>\n",
       "      <td>21607</td>\n",
       "      <td>10419</td>\n",
       "      <td>244032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>900</td>\n",
       "      <td>2502</td>\n",
       "      <td>1931</td>\n",
       "      <td>5333</td>\n",
       "      <td>2605</td>\n",
       "      <td>59995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all</td>\n",
       "      <td>4530</td>\n",
       "      <td>12825</td>\n",
       "      <td>9585</td>\n",
       "      <td>26940</td>\n",
       "      <td>13024</td>\n",
       "      <td>304027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  LOC_count  PER_count  ORG_count  total_count  sentences   words\n",
       "0  train       3630      10323       7654        21607      10419  244032\n",
       "1   test        900       2502       1931         5333       2605   59995\n",
       "2    all       4530      12825       9585        26940      13024  304027"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read - train, test, total\n",
    "#veerud - , LOC, PER, ORG, total märgendid, laused, sonad\n",
    "\n",
    "def split_data(df):\n",
    "    np.random.seed(42)\n",
    "    unique_sentences = df['sentence_id'].unique()\n",
    "    np.random.shuffle(unique_sentences)\n",
    "    split_idx = int(len(unique_sentences) * 0.8)\n",
    "    train_sentences = unique_sentences[:split_idx]\n",
    "    test_sentences = unique_sentences[split_idx:]\n",
    "    train_df = df[df['sentence_id'].isin(train_sentences)]\n",
    "    test_df = df[df['sentence_id'].isin(test_sentences)]\n",
    "    return train_df, test_df\n",
    "\n",
    "all_df = pd.read_csv('data/klaster/filtered_tudeng_bio.csv')\n",
    "train_df, test_df = split_data(all_df)\n",
    "tags = ['LOC', 'PER', 'ORG']\n",
    "\n",
    "dfs = [train_df, test_df, all_df]\n",
    "names = ['train', 'test', 'all']\n",
    "\n",
    "print(len(train_df['sentence_id'].unique()), len(test_df['sentence_id'].unique()), len(all_df['sentence_id'].unique()))\n",
    "\n",
    "rows = []\n",
    "\n",
    "for df, name in zip(dfs, names):\n",
    "    row = [name]\n",
    "    for tag in tags:\n",
    "        row.append(len(df[df['labels'] == f'B-{tag}']))\n",
    "    row.append(sum(row[1:4]))\n",
    "    row.append(len(df['sentence_id'].unique()))\n",
    "    row.append(len(df))\n",
    "    rows.append(row)\n",
    "\n",
    "result_df = pd.DataFrame(data=rows, columns=['name', 'LOC_count', 'PER_count', 'ORG_count', 'total_count', 'sentences', 'words'])\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5d1f513-e012-4095-ad16-de129f782dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     2     3 ... 13020 13022 13023]\n",
      "[    1     4     5 ... 13007 13010 13021]\n"
     ]
    }
   ],
   "source": [
    "def split_data(df):\n",
    "    np.random.seed(42)\n",
    "    unique_sentences = df['sentence_id'].unique()\n",
    "    np.random.shuffle(unique_sentences)\n",
    "    split_idx = int(len(unique_sentences) * 0.8)\n",
    "    train_sentences = unique_sentences[:split_idx]\n",
    "    test_sentences = unique_sentences[split_idx:]\n",
    "    train_df = df[df['sentence_id'].isin(train_sentences)]\n",
    "    test_df = df[df['sentence_id'].isin(test_sentences)]\n",
    "    return train_df, test_df\n",
    "\n",
    "all_df = pd.read_csv('data/klaster/filtered_tudeng_bio.csv')\n",
    "train, test = split_data(all_df)\n",
    "print(train['sentence_id'].unique())\n",
    "print(test['sentence_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80bcb203-7527-4860-a4c1-fba93e5f12fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking consistency across 10 iterations:\n",
      "Iteration 1: Train identical: True, Test identical: True\n",
      "Iteration 2: Train identical: True, Test identical: True\n",
      "Iteration 3: Train identical: True, Test identical: True\n",
      "Iteration 4: Train identical: True, Test identical: True\n",
      "Iteration 5: Train identical: True, Test identical: True\n",
      "Iteration 6: Train identical: True, Test identical: True\n",
      "Iteration 7: Train identical: True, Test identical: True\n",
      "Iteration 8: Train identical: True, Test identical: True\n",
      "Iteration 9: Train identical: True, Test identical: True\n",
      "Iteration 10: Train identical: True, Test identical: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def split_data(df):\n",
    "    np.random.seed(42)  # Setting the same seed each time\n",
    "    unique_sentences = df['sentence_id'].unique()\n",
    "    np.random.shuffle(unique_sentences)\n",
    "    split_idx = int(len(unique_sentences) * 0.8)\n",
    "    train_sentences = unique_sentences[:split_idx]  # Fixed typo from 'rain' to 'train'\n",
    "    test_sentences = unique_sentences[split_idx:]\n",
    "    \n",
    "    # Return the sentence IDs for comparison\n",
    "    return train_sentences, test_sentences\n",
    "\n",
    "# Load your data\n",
    "all_df = pd.read_csv('data/klaster/filtered_tudeng_bio.csv')\n",
    "\n",
    "# Store the first split result to compare with others\n",
    "first_train, first_test = split_data(all_df)\n",
    "\n",
    "# Check if splits are identical across multiple runs\n",
    "print(\"Checking consistency across 10 iterations:\")\n",
    "for i in range(10):\n",
    "    train_sentences, test_sentences = split_data(all_df)\n",
    "    \n",
    "    # Check if the current split matches the first split\n",
    "    train_identical = np.array_equal(train_sentences, first_train)\n",
    "    test_identical = np.array_equal(test_sentences, first_test)\n",
    "    \n",
    "    print(f\"Iteration {i+1}: Train identical: {train_identical}, Test identical: {test_identical}\")\n",
    "    \n",
    "    # Optionally, if they're not identical, you could print the differences:\n",
    "    if not train_identical:\n",
    "        print(f\"  First few train differences: {set(train_sentences[:5]) - set(first_train[:5])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d2e7769a-f9cb-41ae-9f0b-0fe933cf9889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute</th>\n",
       "      <th>estbertner</th>\n",
       "      <th>tudeng</th>\n",
       "      <th>opetaja</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1922-04-24_1936-09-07</td>\n",
       "      <td>0.6025</td>\n",
       "      <td>0.71280</td>\n",
       "      <td>0.53220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1927-03-28_1941-01-03</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.63410</td>\n",
       "      <td>0.47230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1932-01-25</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>0.66380</td>\n",
       "      <td>0.36180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1934-10-15</td>\n",
       "      <td>0.5899</td>\n",
       "      <td>0.73730</td>\n",
       "      <td>0.47000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1935-09-30</td>\n",
       "      <td>0.6876</td>\n",
       "      <td>0.76730</td>\n",
       "      <td>0.48190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5685</td>\n",
       "      <td>0.70306</td>\n",
       "      <td>0.46364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               attribute  estbertner   tudeng  opetaja\n",
       "0  1922-04-24_1936-09-07      0.6025  0.71280  0.53220\n",
       "1  1927-03-28_1941-01-03      0.5600  0.63410  0.47230\n",
       "2             1932-01-25      0.4025  0.66380  0.36180\n",
       "3             1934-10-15      0.5899  0.73730  0.47000\n",
       "4             1935-09-30      0.6876  0.76730  0.48190\n",
       "5                    NaN      0.5685  0.70306  0.46364"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.DataFrame(columns=['attribute', 'estbertner', 'tudeng', 'opetaja'])\n",
    "models = ['estbertner', 'tudeng', 'opetaja']\n",
    "\n",
    "#rows - 5 koikumist, nende keskimine?, kuhugi precision ja callback\n",
    "\n",
    "for filename in os.listdir('final_results/pre_clean_fixed/'):\n",
    "    results_df = pd.read_csv(f'final_results/pre_clean_fixed/{filename}')\n",
    "    if len(filename.split('_')) == 3:\n",
    "        short_name = filename.split('_')[1]\n",
    "    else:\n",
    "        short_name = '_'.join(filename.split('_')[1:3])\n",
    "    temp_row = [short_name]\n",
    "    for model in models:\n",
    "        value = results_df[(results_df['model'] == model) & (results_df['tag'] == 'Overall')]['f1'].iloc[0]\n",
    "        temp_row.append(value)\n",
    "\n",
    "    final_df.loc[len(final_df)] = temp_row\n",
    "final_df.loc[len(final_df)] = final_df.mean(numeric_only=True)\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f201f494-db50-4744-9e29-1fa9fa15cc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model26000_65', 'model13000_70', 'model19500_60', 'model13000_65', 'model19500_65', 'model32500_65', 'model6500_65', 'model19500_70', 'model32500_60', 'model26000_60', 'model6500_75', 'model13000_60', 'model6500_60', 'model39000_60', 'model6500_70'}\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "\n",
    "input_folder = 'final_results/pre_clean_fixed'\n",
    "\n",
    "models_in_all_steps = set()\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    df = pd.read_csv(os.path.join(input_folder, filename))\n",
    "    \n",
    "    if len(models_in_all_steps) == 0:\n",
    "        models_in_all_steps.update(df['model'].unique())\n",
    "    else:\n",
    "        models_in_all_steps = models_in_all_steps & set(df['model'].unique())\n",
    " \n",
    "models_in_all_steps.difference_update({'estbertner', 'opetaja', 'tudeng'})\n",
    "print(models_in_all_steps)\n",
    "print(len(models_in_all_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "423b3e07-08ca-4856-aa55-d69ce8277a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model19500_70', 'model6500_70', 'model32500_60', 'model13000_70', 'model13000_65', 'model19500_65', 'model19500_60', 'model6500_60', 'model6500_65', 'model13000_60', 'model26000_60', 'model6500_75', 'model32500_65', 'model39000_60', 'model26000_65'}\n",
      "----------\n",
      "lavend\n",
      "60    0.688787\n",
      "65    0.679343\n",
      "70    0.660819\n",
      "75    0.649409\n",
      "80    0.603817\n",
      "85    0.435280\n",
      "90    0.224080\n",
      "95    0.051340\n",
      "Name: f1, dtype: float64\n",
      "----------\n",
      "60\n",
      "['model32500_60', 'model19500_60', 'model6500_60', 'model13000_60', 'model26000_60', 'model39000_60']\n",
      "                         mean       std\n",
      "model         lavend                   \n",
      "model13000_60 60      0.68402  0.075221\n",
      "model19500_60 60      0.68474  0.070696\n",
      "model26000_60 60      0.68714  0.072834\n",
      "model32500_60 60      0.69464  0.081142\n",
      "model39000_60 60      0.69240  0.078295\n",
      "model6500_60  60      0.65516  0.066040\n"
     ]
    }
   ],
   "source": [
    "input_folder = 'final_results/pre_clean_fixed'\n",
    "all_dfs = []\n",
    "\n",
    "models_in_all_steps = set()\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    df = pd.read_csv(os.path.join(input_folder, filename))\n",
    "    df['filename'] = filename\n",
    "    all_dfs.append(df)\n",
    "    if len(models_in_all_steps) == 0:\n",
    "        models_in_all_steps.update(df['model'].unique())\n",
    "    else:\n",
    "        models_in_all_steps = models_in_all_steps & set(df['model'].unique())\n",
    "\n",
    "models_in_all_steps.difference_update({'estbertner', 'opetaja', 'tudeng'})\n",
    "print(models_in_all_steps)\n",
    "\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "combined_df['lavend'] = combined_df['model'].str.split('_').str[1]\n",
    "\n",
    "print('-'*10)\n",
    "avg_f1_by_lavend = combined_df[combined_df['tag'] == 'Overall'].groupby(['lavend'])['f1'].mean().sort_index()\n",
    "print(avg_f1_by_lavend)\n",
    "print('-'*10)\n",
    "\n",
    "best_lavend = avg_f1_by_lavend.idxmax()\n",
    "print(best_lavend)\n",
    "\n",
    "best_lavend_models = []\n",
    "for model_name in models_in_all_steps:\n",
    "    if model_name.split('_')[1] == best_lavend:\n",
    "        best_lavend_models.append(model_name)\n",
    "print(best_lavend_models)\n",
    "\n",
    "best_models_from_best_lavend = combined_df[(combined_df['tag'] == 'Overall') & (combined_df['model'].isin(best_lavend_models))]\n",
    "#best_models_from_best_lavend\n",
    "\n",
    "f1_stats_by_model_lavend = best_models_from_best_lavend.groupby(['model', 'lavend'])['f1'].agg(['mean', 'std']).sort_index()\n",
    "\n",
    "print(f1_stats_by_model_lavend)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f335a2b-bb6c-4bcc-9eb6-efb2675045cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_df[(combined_df['tag'] == 'Overall')].groupby(['model', 'lavend'])['f1'].agg(['mean', 'std']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b110d48d-cc1b-4d8c-ad2c-835d35d0596e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model26000_60', 'model19500_65', 'model6500_60', 'model32500_65', 'model13000_70', 'model19500_60', 'model39000_60', 'model32500_60', 'model13000_60', 'model19500_70', 'model6500_75', 'model26000_65', 'model13000_65', 'model6500_70', 'model6500_65'}\n",
      "80\n",
      "results_1922-04-24_1936-09-07_fixed.csv 80 model6500_80 0.6182\n",
      "results_1927-03-28_1941-01-03_fixed.csv 80 model5394_80 0.5806\n",
      "results_1932-01-25_fixed.csv 80 model6500_80 0.5\n",
      "results_1934-10-15_fixed.csv 80 model5115_80 0.5976\n",
      "results_1935-09-30_fixed.csv 80 model6500_80 0.6707\n",
      "95\n",
      "results_1922-04-24_1936-09-07_fixed.csv 95 model103_95 0.0692\n",
      "results_1927-03-28_1941-01-03_fixed.csv 95  0\n",
      "results_1932-01-25_fixed.csv 95 model181_95 0.1875\n",
      "results_1934-10-15_fixed.csv 95  0\n",
      "results_1935-09-30_fixed.csv 95  0\n",
      "90\n",
      "results_1922-04-24_1936-09-07_fixed.csv 90 model759_90 0.1272\n",
      "results_1927-03-28_1941-01-03_fixed.csv 90 model344_90 0.2831\n",
      "results_1932-01-25_fixed.csv 90 model1085_90 0.2723\n",
      "results_1934-10-15_fixed.csv 90 model443_90 0.0032\n",
      "results_1935-09-30_fixed.csv 90 model1240_90 0.4346\n",
      "60\n",
      "results_1922-04-24_1936-09-07_fixed.csv 60 model13000_60 0.7507\n",
      "results_1927-03-28_1941-01-03_fixed.csv 60 model19500_60 0.6915\n",
      "results_1932-01-25_fixed.csv 60 model26000_60 0.5641\n",
      "results_1934-10-15_fixed.csv 60 model13000_60 0.7114\n",
      "results_1935-09-30_fixed.csv 60 model19500_60 0.7257\n",
      "65\n",
      "results_1922-04-24_1936-09-07_fixed.csv 65 model13000_65 0.7406\n",
      "results_1927-03-28_1941-01-03_fixed.csv 65 model26000_65 0.7254\n",
      "results_1932-01-25_fixed.csv 65 model26000_65 0.5665\n",
      "results_1934-10-15_fixed.csv 65 model13000_65 0.7361\n",
      "results_1935-09-30_fixed.csv 65 model6500_65 0.6942\n",
      "70\n",
      "results_1922-04-24_1936-09-07_fixed.csv 70 model19500_70 0.7237\n",
      "results_1927-03-28_1941-01-03_fixed.csv 70 model19500_70 0.6918\n",
      "results_1932-01-25_fixed.csv 70 model23220_70 0.5818\n",
      "results_1934-10-15_fixed.csv 70 model13000_70 0.7179\n",
      "results_1935-09-30_fixed.csv 70 model13000_70 0.6957\n",
      "75\n",
      "results_1922-04-24_1936-09-07_fixed.csv 75 model13000_75 0.6914\n",
      "results_1927-03-28_1941-01-03_fixed.csv 75 model12100_75 0.6722\n",
      "results_1932-01-25_fixed.csv 75 model13000_75 0.564\n",
      "results_1934-10-15_fixed.csv 75 model11736_75 0.6785\n",
      "results_1935-09-30_fixed.csv 75 model13000_75 0.6787\n",
      "85\n",
      "results_1922-04-24_1936-09-07_fixed.csv 85 model2729_85 0.5245\n",
      "results_1927-03-28_1941-01-03_fixed.csv 85 model1787_85 0.3983\n",
      "results_1932-01-25_fixed.csv 85 model3901_85 0.4315\n",
      "results_1934-10-15_fixed.csv 85 model1556_85 0.2333\n",
      "results_1935-09-30_fixed.csv 85 model4745_85 0.5888\n"
     ]
    }
   ],
   "source": [
    "input_folder = 'final_results/pre_clean_fixed'\n",
    "all_dfs = []\n",
    "\n",
    "models_in_all_steps = set()\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    df = pd.read_csv(os.path.join(input_folder, filename))\n",
    "    df['filename'] = filename\n",
    "    all_dfs.append(df)\n",
    "    if len(models_in_all_steps) == 0:\n",
    "        models_in_all_steps.update(df['model'].unique())\n",
    "    else:\n",
    "        models_in_all_steps = models_in_all_steps & set(df['model'].unique())\n",
    "\n",
    "models_in_all_steps.difference_update({'estbertner', 'opetaja', 'tudeng'})\n",
    "print(models_in_all_steps)\n",
    "\n",
    "filter_models = ['tudeng', 'estbertner', 'opetaja']\n",
    "\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "combined_df['lavend'] = combined_df['model'].str.split('_').str[1]\n",
    "\n",
    "combined_df = combined_df[(~combined_df['model'].isin(filter_models)) & (combined_df['tag'] == 'Overall')]\n",
    "group_df = combined_df.groupby('filename')\n",
    "\n",
    "for lavend in grouped_df['lavend'].unique():\n",
    "    print(lavend)\n",
    "    for filename, grouped_df in group_df:\n",
    "        temp_df = grouped_df[grouped_df['lavend'] == lavend].copy()\n",
    "        temp_df['num_tags'] = temp_df['model'].apply(lambda x: x.split('_')[0][5:])\n",
    "        temp_df['num_tags'] = temp_df['num_tags'].astype(int)\n",
    "        temp_df = temp_df.sort_values(by='num_tags', ascending=True)\n",
    "        #print(temp_df)\n",
    "        last_f1 = 0\n",
    "        best_name = ''\n",
    "        for index, row in temp_df.iterrows():\n",
    "            if float(row['f1']) > last_f1:\n",
    "                last_f1 = float(row['f1'])\n",
    "                best_name = row['model']\n",
    "            else:\n",
    "                break\n",
    "        print(filename, lavend, best_name, last_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee099fc9-6a8b-47cb-8166-e80f131fb423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model6500_65', 'model6500_70', 'model6500_75', 'model6500_60', 'model19500_60', 'model32500_65', 'model19500_65', 'model39000_60', 'model13000_70', 'model13000_65', 'model26000_60', 'model26000_65', 'model19500_70', 'model32500_60', 'model13000_60'}\n",
      "60 0.6887\n",
      "65 0.6926\n",
      "70 0.6822\n",
      "75 0.657\n",
      "80 0.5934\n",
      "85 0.4353\n",
      "90 0.2241\n",
      "95 0.0513\n"
     ]
    }
   ],
   "source": [
    "input_folder = 'final_results/pre_clean_fixed'\n",
    "all_dfs = []\n",
    "\n",
    "models_in_all_steps = set()\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    df = pd.read_csv(os.path.join(input_folder, filename))\n",
    "    df['filename'] = filename\n",
    "    all_dfs.append(df)\n",
    "    if len(models_in_all_steps) == 0:\n",
    "        models_in_all_steps.update(df['model'].unique())\n",
    "    else:\n",
    "        models_in_all_steps = models_in_all_steps & set(df['model'].unique())\n",
    "\n",
    "models_in_all_steps.difference_update({'estbertner', 'opetaja', 'tudeng'})\n",
    "print(models_in_all_steps)\n",
    "\n",
    "filter_models = ['tudeng', 'estbertner', 'opetaja']\n",
    "\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "combined_df['lavend'] = combined_df['model'].str.split('_').str[1]\n",
    "\n",
    "combined_df = combined_df[(~combined_df['model'].isin(filter_models)) & (combined_df['tag'] == 'Overall')]\n",
    "group_df = combined_df.groupby('filename')\n",
    "\n",
    "sorted_lavends = sorted(combined_df['lavend'].unique())\n",
    "\n",
    "for lavend in sorted_lavends:\n",
    "    #print(lavend)\n",
    "    f1s = []\n",
    "    for filename, grouped_df in group_df:\n",
    "        temp_df = grouped_df[grouped_df['lavend'] == lavend].copy()\n",
    "        temp_df['num_tags'] = temp_df['model'].apply(lambda x: x.split('_')[0][5:])\n",
    "        temp_df['num_tags'] = temp_df['num_tags'].astype(int)\n",
    "        temp_df = temp_df.sort_values(by='num_tags', ascending=True)\n",
    "        #print(temp_df)\n",
    "        last_f1 = 0\n",
    "        best_name = ''\n",
    "        for index, row in temp_df.iterrows():\n",
    "            if float(row['f1']) > last_f1:\n",
    "                last_f1 = float(row['f1'])\n",
    "                best_name = row['model']\n",
    "            else:\n",
    "                break\n",
    "        f1s.append(last_f1)\n",
    "        #print(filename, lavend, best_name, last_f1)\n",
    "    #print(lavend, round(sum(f1s)/len(f1s), 4), f1s)\n",
    "    print(lavend, round(sum(f1s)/len(f1s), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba49d1b8-69a4-4309-9fcd-25267ca6d4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model6500_65', 'model6500_70', 'model6500_75', 'model6500_60', 'model19500_60', 'model32500_65', 'model19500_65', 'model39000_60', 'model13000_70', 'model13000_65', 'model26000_60', 'model26000_65', 'model19500_70', 'model32500_60', 'model13000_60'}\n",
      "65\n",
      "['estbertner', 'opetaja', 'model6500_65', 'model32500_65', 'model19500_65', 'model13000_65', 'model26000_65']\n",
      "10\n",
      "               mean       std\n",
      "model                        \n",
      "estbertner  0.56850  0.104196\n",
      "opetaja     0.46364  0.062291\n"
     ]
    }
   ],
   "source": [
    "input_folder = 'final_results/pre_clean_fixed_new'\n",
    "all_dfs = []\n",
    "\n",
    "models_in_all_steps = set()\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    df = pd.read_csv(os.path.join(input_folder, filename))\n",
    "    df['filename'] = filename\n",
    "    all_dfs.append(df)\n",
    "    if len(models_in_all_steps) == 0:\n",
    "        models_in_all_steps.update(df['model'].unique())\n",
    "    else:\n",
    "        models_in_all_steps = models_in_all_steps & set(df['model'].unique())\n",
    "\n",
    "models_in_all_steps.difference_update({'estbertner', 'opetaja', 'tudeng'})\n",
    "print(models_in_all_steps)\n",
    "\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "combined_df['lavend'] = combined_df['model'].str.split('_').str[1]\n",
    "\n",
    "best_lavend = '65'\n",
    "print(best_lavend)\n",
    "\n",
    "best_lavend_models = ['estbertner', 'opetaja']\n",
    "for model_name in models_in_all_steps:\n",
    "    if model_name.split('_')[1] == best_lavend:\n",
    "        best_lavend_models.append(model_name)\n",
    "print(best_lavend_models)\n",
    "\n",
    "best_models_from_best_lavend = combined_df[(combined_df['tag'] == 'Overall') & (combined_df['model'].isin(['estbertner', 'opetaja']))]\n",
    "#best_models_from_best_lavend\n",
    "print(len(best_models_from_best_lavend))\n",
    "f1_stats_by_model_lavend = best_models_from_best_lavend.groupby(['model'])['f1'].agg(['mean', 'std']).sort_index()\n",
    "\n",
    "print(f1_stats_by_model_lavend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "524ce510-51ef-4222-ae7b-2c71321f50e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision\n",
      "                  mean       std\n",
      "model                           \n",
      "estbertner     0.66546  0.147635\n",
      "model32500_65  0.69714  0.105477\n",
      "opetaja        0.42124  0.083282\n",
      "tudeng         0.68262  0.089578\n",
      "\n",
      "recall\n",
      "                  mean       std\n",
      "model                           \n",
      "estbertner     0.50000  0.084498\n",
      "model32500_65  0.68068  0.043715\n",
      "opetaja        0.52286  0.041060\n",
      "tudeng         0.70400  0.044707\n",
      "\n",
      "f1\n",
      "                  mean       std\n",
      "model                           \n",
      "estbertner     0.56850  0.104196\n",
      "model32500_65  0.68738  0.073589\n",
      "opetaja        0.46364  0.062291\n",
      "tudeng         0.69166  0.063019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = ['model32500_65', 'opetaja', 'estbertner', 'tudeng']\n",
    "input_folder = 'final_results/pre_clean_fixed_new'\n",
    "all_dfs = []\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    df = pd.read_csv(os.path.join(input_folder, filename))\n",
    "    df['filename'] = filename\n",
    "    all_dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "combined_df['lavend'] = combined_df['model'].str.split('_').str[1]\n",
    "\n",
    "stats = ['precision', 'recall', 'f1']\n",
    "\n",
    "specific_models_df = combined_df[(combined_df['tag'] == 'Overall') & (combined_df['model'].isin(models))]\n",
    "for stat in stats:\n",
    "    results = specific_models_df.groupby(['model'])[stat].agg(['mean', 'std']).sort_index()\n",
    "    print(stat)\n",
    "    print(results)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "574a706c-a8f2-4d13-b58b-52ab11ff24b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  estbertner            opetaja      model32500_65  \\\n",
      "precision  & 0.6655\\pm0.1476  & 0.4212\\pm0.0833  & 0.6971\\pm0.1055   \n",
      "recall     & 0.5000\\pm0.0845  & 0.5229\\pm0.0411  & 0.6807\\pm0.0437   \n",
      "f1         & 0.5685\\pm0.1042  & 0.4636\\pm0.0623  & 0.6874\\pm0.0736   \n",
      "\n",
      "                      tudeng  \n",
      "precision  & 0.6826\\pm0.0896  \n",
      "recall     & 0.7040\\pm0.0447  \n",
      "f1         & 0.6917\\pm0.0630  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:27: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:27: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\Norman\\AppData\\Local\\Temp\\ipykernel_9320\\4053160571.py:27: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  results_df.loc[stat, model] = f\"& {mean_val:.4f}\\pm{std_val:.4f}\"\n"
     ]
    }
   ],
   "source": [
    "models = ['estbertner', 'opetaja', 'model32500_65', 'tudeng']\n",
    "input_folder = 'final_results/pre_clean_fixed_new'\n",
    "all_dfs = []\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    df = pd.read_csv(os.path.join(input_folder, filename))\n",
    "    df['filename'] = filename\n",
    "    all_dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "combined_df['lavend'] = combined_df['model'].str.split('_').str[1]\n",
    "\n",
    "# Filter for specific models and the Overall tag\n",
    "specific_models_df = combined_df[(combined_df['tag'] == 'Overall') & \n",
    "                                (combined_df['model'].isin(models))]\n",
    "\n",
    "# Create an empty DataFrame to store results\n",
    "results_df = pd.DataFrame(index=['precision', 'recall', 'f1'])\n",
    "\n",
    "# Populate the DataFrame\n",
    "for model in models:\n",
    "    model_data = specific_models_df[specific_models_df['model'] == model]\n",
    "    for stat in ['precision', 'recall', 'f1']:\n",
    "        mean_val = model_data[stat].mean()\n",
    "        std_val = model_data[stat].std()\n",
    "        # Format as \"mean ± std\"\n",
    "        results_df.loc[stat, model] = f\"& {mean_val:.4f}\\pm{std_val:.4f}\"\n",
    "\n",
    "# Print the reshaped results\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
